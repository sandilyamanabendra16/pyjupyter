{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0f46b56",
   "metadata": {},
   "source": [
    "## Clustering\n",
    "Clustering is the task of dividing the population or data points into a number of groups such that data points in the same groups are more similar to other data points in the same group than those in other groups. In simple words, the aim is to segregate groups with similar traits and assign them into clusters.\n",
    "\n",
    "KMeans Clustering\n",
    "K-means clustering is one of the simplest and popular unsupervised machine learning algorithms. You’ll define a target number k, which refers to the number of centroids you need in the dataset. A centroid is the imaginary or real location representing the center of the cluster. Every data point is allocated to each of the clusters through reducing the in-cluster sum of squares. In other words, the K-means algorithm identifies k number of centroids, and then allocates every data point to the nearest cluster, while keeping the centroids as small as possible. The ‘means’ in the K-means refers to averaging of the data; that is, finding the centroid.\n",
    "https://www.kaggle.com/code/heeraldedhia/kmeans-clustering-for-customer-data/notebook\n",
    "https://ganpat-patel-012.github.io/Customer-Segmentation-Exopsys-Data-Labs-Internship/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ff1cfe",
   "metadata": {},
   "source": [
    "dataLink = 'https://raw.githubusercontent.com/DUanalytics/datasets/master/csv/clusteringMallCustomers.csv'\n",
    "This input file contains the basic information (ID, age, gender, income, spending score) about the customers of a mall. Spending Score is something you assign to the customer based on your defined parameters like customer behavior and purchasing data.\n",
    "You own the mall and want to understand the customers like who can be easily converge [Target Customers] so that the sense can be given to marketing team and plan the strategy accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c34d63c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'plotly'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-2106d8962731>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mplotly\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_objs\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'plotly'"
     ]
    }
   ],
   "source": [
    "# libraries\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "\n",
    "import plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honest-african",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting plotly\n",
      "  Downloading plotly-5.13.1-py2.py3-none-any.whl (15.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 15.2 MB 379 kB/s eta 0:00:01    |██████████████                  | 6.7 MB 3.1 MB/s eta 0:00:03     |████████████████████████▊       | 11.8 MB 3.3 MB/s eta 0:00:02     |███████████████████████████▊    | 13.2 MB 3.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tenacity>=6.2.0\n",
      "  Downloading tenacity-8.2.2-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: tenacity, plotly\n"
     ]
    }
   ],
   "source": [
    "!pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933d53a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa94a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/DUanalytics/datasets/master/csv/clusteringMallCustomers.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e0f608",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2910da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd0d537",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae2abdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['customerID','gender','age','annualIncome','spendingScore']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd67853",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c37ff87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Null Values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4f0941",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df['age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52951419",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1, figsize=(10,6))\n",
    "n = 0\n",
    "for x in ['age','annualIncome', 'spendingScore']:\n",
    "    n = n + 1\n",
    "    plt.subplot(1, 3, n)\n",
    "    plt.subplots_adjust(hspace = 0.5, wspace = .5)\n",
    "    sns.distplot(df[x], bins=5)\n",
    "    plt.title('Distribution Plot of {}'.format(x))\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121aa471",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df, vars = ['age','annualIncome', 'spendingScore'], hue='gender')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a420d321",
   "metadata": {},
   "source": [
    "### 2D Clustering based on Age and Spending Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f622e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1 , figsize = (15 , 7))\n",
    "plt.title('Scatter plot of Age v/s Spending Score', fontsize = 20)\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Spending Score')\n",
    "plt.scatter( x = 'age', y = 'spendingScore', data = df, s = 100)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca3801b",
   "metadata": {},
   "source": [
    "### k value\n",
    "Inertia measures how well a dataset was clustered by K-Means. It is calculated by measuring the distance between each data point and its centroid, squaring this distance, and summing these squares across one cluster. A good model is one with low inertia AND a low number of clusters ( K )."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8444324a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = df[['age', 'spendingScore']].values\n",
    "X1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7457dca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=2\n",
    "Aks = KMeans(n_clusters=n, init='k-means++', n_init=10, max_iter=300, tol = .001, random_state=111, algorithm ='elkan')\n",
    "Aks.fit(X1)\n",
    "round(Aks.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8e96a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=4\n",
    "Aks = KMeans(n_clusters=n, init='k-means++', n_init=10, max_iter=300, tol = .001, random_state=111, algorithm ='elkan')\n",
    "Aks.fit(X1)\n",
    "round(Aks.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798b441d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inertia changes as we change n, no of clusters\n",
    "#Optimal Number of cluster ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb8efe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "inertia = []\n",
    "for n in range(1, 15):\n",
    "    Aks = KMeans(n_clusters=n, init='k-means++', n_init=10, max_iter=300, tol = .001, random_state=111, algorithm ='elkan')\n",
    "    Aks.fit(X1)\n",
    "    inertia.append(round(Aks.inertia_))\n",
    "print(inertia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ad6bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot and check inertia and n values\n",
    "plt.figure(1 , figsize = (15 ,6))\n",
    "plt.plot(np.arange(1 , 15) , inertia , 'o')\n",
    "plt.plot(np.arange(1 , 15) , inertia , '-' , alpha = 0.5)\n",
    "plt.xlabel('Number of Clusters') , plt.ylabel('Inertia')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ade02df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# elbow points - k = 4\n",
    "n=4\n",
    "Aks4 = KMeans(n_clusters=n, init='k-means++', n_init=10, max_iter=300, tol = .001, random_state=111, algorithm ='elkan')\n",
    "Aks4.fit(X1)\n",
    "round(Aks4.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08353986",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels4 = Aks4.labels_\n",
    "centeriods4 = Aks4.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5688122f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(labels4)\n",
    "# to which cluster each row of data belongs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c770b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(centeriods4)\n",
    "# center point of each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791d4100",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cluster1'] = pd.DataFrame(labels4)\n",
    "df.sort_values(by='cluster1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fbfb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.cluster1.value_counts()\n",
    "#clusters =['0','1','2','3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9b81a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1 , figsize = (15 , 7))\n",
    "plt.title('Scatter plot of Age v/s Spending Score', fontsize = 20)\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Spending Score')\n",
    "plt.scatter( x = 'age', y = 'spendingScore', data = df, s = 100, c='cluster1')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060c71b4",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "sns.scatterplot(df['age'], df['spendingScore'],hue=['cluster1'] ,alpha=0.6)\n",
    "plt.title('Cluster Wise Colors : Age vs Spending Score', fontsize = 15)\n",
    "plt.xlabel('Age', fontsize = 12)\n",
    "plt.ylabel('Spending Score', fontsize = 12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e1e1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Use all numeric Columns\n",
    "X2 = df[['age', 'annualIncome','spendingScore']].values\n",
    "X2[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0106a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "inertia = []\n",
    "for n in range(1, 15):\n",
    "    Aks = KMeans(n_clusters=n, init='k-means++', n_init=10, max_iter=300, tol = .001, random_state=111, algorithm ='elkan')\n",
    "    Aks.fit(X2)\n",
    "    inertia.append(round(Aks.inertia_))\n",
    "print(inertia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c83e4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot and check inertia and n values\n",
    "plt.figure(1 , figsize = (15 ,6))\n",
    "plt.plot(np.arange(1 , 15) , inertia , 'o')\n",
    "plt.plot(np.arange(1 , 15) , inertia , '-' , alpha = 0.5)\n",
    "plt.xlabel('Number of Clusters') , plt.ylabel('Inertia')\n",
    "plt.show();\n",
    "#n=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc39dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=6\n",
    "Aks6 = KMeans(n_clusters=n, init='k-means++', n_init=10, max_iter=300, tol = .001, random_state=111, algorithm ='elkan')\n",
    "Aks6.fit(X2)\n",
    "round(Aks6.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488e8313",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels6 = Aks6.labels_\n",
    "centeriods6 = Aks6.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8c3b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cluster2'] = pd.DataFrame(labels6)\n",
    "df.sort_values(by='cluster2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630e47e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.cluster2.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b23e8c",
   "metadata": {},
   "source": [
    "## Plotly 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da61111d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "trace1 = go.Scatter3d (\n",
    "    x= df['age'],   y= df['spendingScore'], z= df['annualIncome'],\n",
    "    mode='markers',marker=dict( color = df['cluster2'],  size= 10, \n",
    "    line=dict( color= df['cluster2'], width= 12),  opacity=0.8  )\n",
    ")\n",
    "data = [trace1]\n",
    "layout = go.Layout(\n",
    "    title= 'Clusters wrt Age, Income and Spending Scores',\n",
    "    scene = dict(\n",
    "            xaxis = dict(title  = 'Age'),\n",
    "            yaxis = dict(title  = 'Spending Score'),\n",
    "            zaxis = dict(title  = 'Annual Income')\n",
    "        )\n",
    ")\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.offline.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b8a802",
   "metadata": {},
   "source": [
    "We analysed Customer data and performed 2D and 3D clustering using K Means Algorithm. This kind of cluster analysis helps design better customer acquisition strategies and helps in business growth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d015ebce",
   "metadata": {},
   "source": [
    "more\n",
    "meshgrid, scaling of data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad0fddd",
   "metadata": {},
   "source": [
    "## Hierarchical Clustering\n",
    "We merge the most similar points or clusters in hierarchical clustering – we know this. Now the question is – how do we decide which points are similar and which are not?\n",
    "way to calculate similarity – Take the distance between the centroids of these clusters. The points having the least distance are referred to as similar points and we can merge them. We can refer to this as a distance-based algorithm as well (since we are calculating the distances between the clusters).\n",
    "\n",
    "In hierarchical clustering, we have a concept called a proximity matrix. This stores the distances between each point. Let’s take an example to understand this matrix as well as the steps to perform hierarchical clustering.\n",
    "https://www.analyticsvidhya.com/blog/2019/05/beginners-guide-hierarchical-clustering/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21ee2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "XH = df[['age','annualIncome', 'spendingScore']].values\n",
    "XH[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12976468",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236d221e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c1b6e8ac",
   "metadata": {},
   "source": [
    "### Dendogram\n",
    "A dendrogram is a tree-like diagram that records the sequences of merges or splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a95f9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "linkage_data = linkage(XH[1:5], method='ward', metric='euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f46bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dendrogram(linkage_data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f740e5",
   "metadata": {},
   "source": [
    "The vertical line represents the distance between these samples. Similarly, we plot all the steps where we merged the clusters and finally, we get a dendrogram like this:\n",
    "More the distance of the vertical lines in the dendrogram, more the distance between those clusters.\n",
    "we can set a threshold distance and draw a horizontal line (Generally, we try to set the threshold in such a way that it cuts the tallest vertical line)\n",
    "The number of clusters will be the number of vertical lines which are being intersected by the line drawn using the threshold. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7e553f",
   "metadata": {},
   "source": [
    "### Agglomerative Clustering (n to 1) : join\n",
    "We assign each point to an individual cluster in this technique. Suppose there are 4 data points. We will assign each of these points to a cluster and hence will have 4 clusters in the beginning:\n",
    "Then, at each iteration, we merge the closest pair of clusters and repeat this step until only a single cluster is left:\n",
    "We are merging (or adding) the clusters at each step, right? Hence, this type of clustering is also known as additive hierarchical clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376cd5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "HC = AgglomerativeClustering(n_clusters=2, affinity='euclidean', linkage='ward')\n",
    "HC_labels = HC.fit_predict(XH[1:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f1da9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "HC_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bceb9109",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1st and 3rd in 1 cluster\n",
    "#2nd and 4th in 2nd cluster\n",
    "XH[1:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a773e634",
   "metadata": {},
   "source": [
    "### Divisive Clustering ( 1 to n ) : separate\n",
    "Divisive hierarchical clustering works in the opposite way. Instead of starting with n clusters (in case of n observations), we start with a single cluster and assign all the points to that cluster.\n",
    "\n",
    "So, it doesn’t matter if we have 10 or 1000 data points. All these points will belong to the same cluster at the beginning:\n",
    "Now, at each iteration, we split the farthest point in the cluster and repeat this process until each cluster only contains a single point:\n",
    "We are splitting (or dividing) the clusters at each step, hence the name divisive hierarchical clustering.\n",
    "Agglomerative Clustering is widely used in the industry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5892b762",
   "metadata": {},
   "source": [
    "### Scale Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace714ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfH = pd.read_csv('https://raw.githubusercontent.com/DUanalytics/datasets/master/csv/clusteringMallCustomers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9cf014",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfH.columns = ['customerID','gender','age','annualIncome','spendingScore']\n",
    "dfH.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12413e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfH.drop(['gender'], axis=1, inplace=True)\n",
    "dfH.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a06ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "data_scaled = normalize(dfH)\n",
    "data_scaled = pd.DataFrame(data_scaled, columns=dfH.columns)\n",
    "data_scaled.head()\n",
    "# scale of all the variables is almost similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9f453e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_scaled.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0efda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.cluster.hierarchy as shc\n",
    "plt.figure(figsize=(10, 7))  \n",
    "plt.title(\"Dendrograms\")  \n",
    "dend = shc.dendrogram(shc.linkage(data_scaled, method='ward'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56c71b3",
   "metadata": {},
   "source": [
    "The x-axis contains the samples and y-axis represents the distance between these samples. The vertical line with maximum distance is the blue line and hence we can decide a threshold of x and cut the dendrogram:\n",
    "https://youtu.be/ijUMKMC4f9I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39547593",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fff314",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))  \n",
    "plt.title(\"Dendrograms\")  \n",
    "dend = shc.dendrogram(shc.linkage(data_scaled, method='ward'))\n",
    "plt.axhline(y=2, color='r', linestyle='--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb72a4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# height is max when joining two cluster.. \n",
    "dend = shc.dendrogram(shc.linkage(data_scaled, method='ward'))\n",
    "#print(dend)\n",
    "print(set(dend['color_list']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca82c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "cluster = AgglomerativeClustering(n_clusters=4, affinity='euclidean', linkage='ward')  \n",
    "cluster.fit_predict(data_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5f6883",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))  \n",
    "plt.scatter(data_scaled['age'], data_scaled['annualIncome'], c=cluster.labels_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb7d459",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))  \n",
    "plt.scatter(dfH['age'], dfH['annualIncome'], c=cluster.labels_) \n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382dd0e8",
   "metadata": {},
   "source": [
    "https://plotly.com/python/dendrogram/\n",
    "https://www.youtube.com/watch?v=4DInt3H2UNE    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
